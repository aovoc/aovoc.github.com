---
layout: post
category : GAN
tagline: ""
tags : [GAN, DL]
---

nvidia 使用GAN生成高清晰图像论文：

     PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION

github地址：https://github.com/tkarras/progressive_growing_of_gans

# 贡献  
- 提出新的训练的策略：对生成器和判别器从低分辨率开始，逐步地增长生成器和判别器的尺寸进行训练。

- 提出生成多样化图像的简单方法。

- 提出了一些减弱生成器和判别器不正当竞争的的实现细节。


- 提出gan图像生成的评判标准。

# Loss   
    WGAN-GP loss

# 贡献点详解     
## 1.逐步增长的训练策略    

从低分辨率开始训练，之后不断地在网络上添加层来进行更高分辨率的图像生成的训练。生成器和判别器的网络互为镜像，在整个训练过程中网络的所有层都保持在更新状态。

训练过程如下图：   
<img src="/assets/pics/nvidia-HD-training-process.JPG" alt="训练过程"/>

### 分辨率提升和降低方法    

相邻层尺寸放大及缩小一倍使用的方法：最近邻插值和平均池化

### 优点   
- 在生成高分辨率的图像的过程中保持训练的稳定性

- 减少训练的时间

分辨率转换的过程如下：

<img src="/assets/pics/nvidia-hd-resolution-transfer.JPG" alt="分辨率转换过程"/>


fromRGB、toRGB 颜色空间和特征空间的转换，使用1*1的卷积

使用类似残差模块的结构进行分辨率的转换。

## 2.使用小批量标准差来增加生成图像的多样性

GAN有只能捕捉到训练数据的一小部分子集的变化的特性

解决方法：小批量辨别

通过在判别器的后边添加一个小批量层次来实现

在文中对这种方法进行了简化来提高变化空间的大小

简化方案：

- 对每个特征在每个空间位置计算小批量数据的标准差

- 对所有的特征和所有的空间位置的第一步得到的计算值进行求平均得到一个值。

- 在每个空间位置将值进行重复得到一个常量值的特征层并将它连接到所有的特征空间上


此外，通过实验发现将特征层放在最后一层能得到最好的效果。


## 3.通过正则化来提升训练的稳定性   
### 对权重进行动态正则化    

通过对权重的动态正则化来保证所有权重的学习速率是相同的

### 在生成器中对特征向量进行像素级别的正则化    

为了解决生成器和判别器在竞争中出现的信号规模失去控制的现象

解决方案：通过使用变化的“局部响应正则化”,公式如下

<img src="/assets/pics/nvidia-hd-formula.JPG" alt="局部响应正则化公式"/>


其中，b_{x, y} 是变化后的特征，a_{x, y} 是变化之前的特征。


## 4.新的图像变换的质量和变化程度的衡量机制

略


# 网络结构

在celebA数据集上生成高清图像采用的网络结构如下图：     

<img src="/assets/pics/nvidia-hd-network.JPG" alt="网络结构"/>




