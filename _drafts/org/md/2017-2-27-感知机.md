---
layout: post
category : statistical learning
tagline: ""
tags : [statistical learning]
---

# Table of Contents

1.  [感知机模型](#org9830932)
2.  [感知机学习策略](#org9ada2ab)
    1.  [数据集的线性可分性](#org4a04c57)
    2.  [感知机学习策略](#orge6755d2)
3.  [感知机学习算法](#orgb21b81f)
    1.  [感知机学习算法的原始形式](#org65e44b2)
    2.  [算法的收敛性](#org3c3ce63)

二类分类的线性分类模型
输入：实例的特征向量 输出：实例的类别


<a id="org9830932"></a>

# 感知机模型

f(x) = sign(w\*x + b)
  if(x >= 0) sign(x) = 1;
  else sign(x) = -1;


<a id="org9ada2ab"></a>

# 感知机学习策略


<a id="org4a04c57"></a>

## 数据集的线性可分性


<a id="orge6755d2"></a>

## 感知机学习策略

确定学习策略，即定义损失函数并使损失函数最小化
感知机采用损失函数输入特征：误分类点到超平面的距离
感知机损失函数定义: 
<img src="/assets/pics/2017-2-27-感知机_ab7214279dec2ff9cd602f6693b6cc27b8fc3624.png" alt="2017-2-27-感知机_ab7214279dec2ff9cd602f6693b6cc27b8fc3624.png" />
其中，M是误分类点的集合。
给定数据集T,损失函数是w,b的连续可导函数


<a id="orgb21b81f"></a>

# 感知机学习算法

求解损失函数的最优化问题的方法。 
梯度下降法， 原始形式、对偶形式


<a id="org65e44b2"></a>

## 感知机学习算法的原始形式

误分类驱动 梯度下降法
一次随机选取一个误分类点使其梯度下降
随机选取一个误分类点 <img src="/assets/pics/2017-2-27-感知机_06641331faffdb0a4e8760a85a6d0c89574f04bb.png" alt="2017-2-27-感知机_06641331faffdb0a4e8760a85a6d0c89574f04bb.png" /> , 对w,b进行更新：
<img src="/assets/pics/2017-2-27-感知机_5bf47d31598ba1e635ab0bb53b944075b0517561.png" alt="2017-2-27-感知机_5bf47d31598ba1e635ab0bb53b944075b0517561.png" />
采用不同的初值或者选取不同的分类点，解可以不同。


<a id="org3c3ce63"></a>

## 算法的收敛性

当训练数据集线性可分时，感知机学习算法原始形式是迭代收敛的，当不可分时，迭代不收敛

